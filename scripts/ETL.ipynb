{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb21284",
   "metadata": {},
   "source": [
    "#### ***Extract***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7949101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Extraction process\n",
    "try:\n",
    "    df_financials = pd.read_csv(r\"C:\\Users\\your_user\\your_folder\\constituents-financials_csv.csv\")\n",
    "    df_esg = pd.read_csv(r\"C:\\Users\\your_user\\your_folder\\SP 500 ESG Risk Ratings.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9eed232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis: Financials (df_financials)\n",
      "\n",
      " Info Schema and Data Types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Symbol          505 non-null    object \n",
      " 1   Name            505 non-null    object \n",
      " 2   Sector          505 non-null    object \n",
      " 3   Price           505 non-null    float64\n",
      " 4   Price/Earnings  503 non-null    float64\n",
      " 5   Dividend Yield  505 non-null    float64\n",
      " 6   Earnings/Share  505 non-null    float64\n",
      " 7   52 Week Low     505 non-null    float64\n",
      " 8   52 Week High    505 non-null    float64\n",
      " 9   Market Cap      505 non-null    int64  \n",
      " 10  EBITDA          505 non-null    float64\n",
      " 11  Price/Sales     505 non-null    float64\n",
      " 12  Price/Book      497 non-null    float64\n",
      " 13  SEC Filings     505 non-null    object \n",
      "dtypes: float64(9), int64(1), object(4)\n",
      "memory usage: 55.4+ KB\n",
      "\n",
      " Head Sample Data:\n",
      "  Symbol                 Name                  Sector   Price  Price/Earnings  \\\n",
      "0    MMM           3M Company             Industrials  222.89           24.31   \n",
      "1    AOS      A.O. Smith Corp             Industrials   60.24           27.76   \n",
      "2    ABT  Abbott Laboratories             Health Care   56.27           22.51   \n",
      "3   ABBV          AbbVie Inc.             Health Care  108.48           19.41   \n",
      "4    ACN        Accenture plc  Information Technology  150.51           25.47   \n",
      "\n",
      "   Dividend Yield  Earnings/Share  52 Week Low  52 Week High    Market Cap  \\\n",
      "0        2.332862            7.92       259.77       175.490  138721055226   \n",
      "1        1.147959            1.70        68.39        48.925   10783419933   \n",
      "2        1.908982            0.26        64.60        42.280  102121042306   \n",
      "3        2.499560            3.29       125.86        60.050  181386347059   \n",
      "4        1.714470            5.44       162.60       114.820   98765855553   \n",
      "\n",
      "         EBITDA  Price/Sales  Price/Book  \\\n",
      "0  9.048000e+09     4.390271       11.34   \n",
      "1  6.010000e+08     3.575483        6.35   \n",
      "2  5.744000e+09     3.740480        3.19   \n",
      "3  1.031000e+10     6.291571       26.14   \n",
      "4  5.643228e+09     2.604117       10.62   \n",
      "\n",
      "                                         SEC Filings  \n",
      "0  http://www.sec.gov/cgi-bin/browse-edgar?action...  \n",
      "1  http://www.sec.gov/cgi-bin/browse-edgar?action...  \n",
      "2  http://www.sec.gov/cgi-bin/browse-edgar?action...  \n",
      "3  http://www.sec.gov/cgi-bin/browse-edgar?action...  \n",
      "4  http://www.sec.gov/cgi-bin/browse-edgar?action...  \n",
      "\n",
      " Numeric Statistics:\n",
      "             Price  Price/Earnings  Dividend Yield  Earnings/Share  \\\n",
      "count   505.000000      503.000000      505.000000      505.000000   \n",
      "mean    103.830634       24.808390        1.895953        3.753743   \n",
      "std     134.427636       41.241081        1.537214        5.689036   \n",
      "min       2.820000     -251.530000        0.000000      -28.010000   \n",
      "25%      46.250000       15.350000        0.794834        1.490000   \n",
      "50%      73.920000       19.450000        1.769255        2.890000   \n",
      "75%     116.540000       25.750000        2.781114        5.140000   \n",
      "max    1806.060000      520.150000       12.661196       44.090000   \n",
      "\n",
      "       52 Week Low  52 Week High    Market Cap        EBITDA  Price/Sales  \\\n",
      "count   505.000000    505.000000  5.050000e+02  5.050000e+02   505.000000   \n",
      "mean    122.623832     83.536616  4.923944e+10  3.590328e+09     3.941705   \n",
      "std     155.362140    105.725473  9.005017e+10  6.840544e+09     3.460110   \n",
      "min       6.590000      2.800000  2.626102e+09 -5.067000e+09     0.153186   \n",
      "25%      56.250000     38.430000  1.273207e+10  7.739320e+08     1.629490   \n",
      "50%      86.680000     62.850000  2.140095e+10  1.614399e+09     2.896440   \n",
      "75%     140.130000     96.660000  4.511968e+10  3.692749e+09     4.703842   \n",
      "max    2067.990000   1589.000000  8.095080e+11  7.938600e+10    20.094294   \n",
      "\n",
      "        Price/Book  \n",
      "count   497.000000  \n",
      "mean     14.453179  \n",
      "std      89.660508  \n",
      "min       0.510000  \n",
      "25%       2.020000  \n",
      "50%       3.400000  \n",
      "75%       6.110000  \n",
      "max    1403.380000  \n"
     ]
    }
   ],
   "source": [
    "# Analysis of Financials (df_financials)\n",
    "print(\"Analysis: Financials (df_financials)\")\n",
    "print(\"\\n Info Schema and Data Types:\")\n",
    "df_financials.info()\n",
    "print(\"\\n Head Sample Data:\")\n",
    "print(df_financials.head())\n",
    "\n",
    "# Statistical summary of numeric columns\n",
    "print(\"\\n Numeric Statistics:\")\n",
    "print(df_financials.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7fcbe",
   "metadata": {},
   "source": [
    "Main Finding: \n",
    "\n",
    "Two columns are inverted. The 52 Week Low and 52 Week High columns have logical differences. The describe statistics confirs that the mean for Low $122.62 > mean High $83.53. Therefore, in our transformation process will swap them.\n",
    "\n",
    "Minor Issues:\n",
    "\n",
    "Nulls: There are minor, acceptable data gaps. 2 companies are missing Price/Earnings (505 - 503 = 2), and 8 are missing Price/Book (505 - 497 = 8). This isn't an error, it's just incomplete data we'll have to live with.\n",
    "\n",
    "Cleanup: The SEC Filings column is confirmed as object (text) and is not needed for our KPIs. It will be dropped.\n",
    "\n",
    "File Quality: Our output shows Price/Earnings is already a float64 (numeric), which is good. The file is cleaner than we might have assumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24420d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis: ESG (df_esg)\n",
      "\n",
      " Info Schema and Data Types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503 entries, 0 to 502\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Symbol                  503 non-null    object \n",
      " 1   Name                    503 non-null    object \n",
      " 2   Address                 502 non-null    object \n",
      " 3   Sector                  502 non-null    object \n",
      " 4   Industry                502 non-null    object \n",
      " 5   Full Time Employees     498 non-null    object \n",
      " 6   Description             502 non-null    object \n",
      " 7   Total ESG Risk score    430 non-null    float64\n",
      " 8   Environment Risk Score  430 non-null    float64\n",
      " 9   Governance Risk Score   430 non-null    float64\n",
      " 10  Social Risk Score       430 non-null    float64\n",
      " 11  Controversy Level       430 non-null    object \n",
      " 12  Controversy Score       403 non-null    float64\n",
      " 13  ESG Risk Percentile     430 non-null    object \n",
      " 14  ESG Risk Level          430 non-null    object \n",
      "dtypes: float64(5), object(10)\n",
      "memory usage: 59.1+ KB\n",
      "\n",
      " Head Sample Data:\n",
      "  Symbol                      Name  \\\n",
      "0   ENPH      Enphase Energy, Inc.   \n",
      "1    EMN  Eastman Chemical Company   \n",
      "2    DPZ       Domino's Pizza Inc.   \n",
      "3    DAY            Dayforce, Inc.   \n",
      "4    DVA               Davita Inc.   \n",
      "\n",
      "                                             Address             Sector  \\\n",
      "0  47281 Bayside Parkway\\nFremont, CA 94538\\nUnit...         Technology   \n",
      "1  200 South Wilcox Drive\\nKingsport, TN 37662\\nU...    Basic Materials   \n",
      "2  30 Frank Lloyd Wright Drive\\nAnn Arbor, MI 481...  Consumer Cyclical   \n",
      "3  3311 East Old Shakopee Road\\nMinneapolis, MN 5...         Technology   \n",
      "4  2000 16th Street\\nDenver, CO 80202\\nUnited States         Healthcare   \n",
      "\n",
      "                  Industry Full Time Employees  \\\n",
      "0                    Solar               3,157   \n",
      "1      Specialty Chemicals              14,000   \n",
      "2              Restaurants               6,500   \n",
      "3   Software - Application               9,084   \n",
      "4  Medical Care Facilities              70,000   \n",
      "\n",
      "                                         Description  Total ESG Risk score  \\\n",
      "0  Enphase Energy, Inc., together with its subsid...                   NaN   \n",
      "1  Eastman Chemical Company operates as a special...                  25.3   \n",
      "2  Domino's Pizza, Inc., through its subsidiaries...                  29.2   \n",
      "3  Dayforce Inc., together with its subsidiaries,...                   NaN   \n",
      "4  DaVita Inc. provides kidney dialysis services ...                  22.6   \n",
      "\n",
      "   Environment Risk Score  Governance Risk Score  Social Risk Score  \\\n",
      "0                     NaN                    NaN                NaN   \n",
      "1                    12.8                    6.6                5.8   \n",
      "2                    10.6                    6.3               12.2   \n",
      "3                     NaN                    NaN                NaN   \n",
      "4                     0.1                    8.4               14.1   \n",
      "\n",
      "            Controversy Level  Controversy Score ESG Risk Percentile  \\\n",
      "0                         NaN                NaN                 NaN   \n",
      "1  Moderate Controversy Level                2.0     50th percentile   \n",
      "2  Moderate Controversy Level                2.0     66th percentile   \n",
      "3                         NaN                NaN                 NaN   \n",
      "4  Moderate Controversy Level                2.0     38th percentile   \n",
      "\n",
      "  ESG Risk Level  \n",
      "0            NaN  \n",
      "1         Medium  \n",
      "2         Medium  \n",
      "3            NaN  \n",
      "4         Medium  \n"
     ]
    }
   ],
   "source": [
    "# Analysis of ESG (df_esg)\n",
    "print(\"Analysis: ESG (df_esg)\")\n",
    "print(\"\\n Info Schema and Data Types:\")\n",
    "df_esg.info()\n",
    "print(\"\\n Head Sample Data:\")\n",
    "print(df_esg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5f7ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Unique 'Controversy Level' values:\n",
      "[nan 'Moderate Controversy Level' 'Low Controversy Level'\n",
      " 'Severe Controversy Level' 'None Controversy Level'\n",
      " 'Significant Controversy Level' 'High Controversy Level']\n",
      "\n",
      " Unique 'ESG Risk Percentile' values (first 10):\n",
      "[nan '50th percentile' '66th percentile' '38th percentile'\n",
      " '59th percentile' '23rd percentile' '53rd percentile' '28th percentile'\n",
      " '21st percentile' '55th percentile']\n"
     ]
    }
   ],
   "source": [
    "# checking text-based columns we need to clean\n",
    "print(\"\\n Unique 'Controversy Level' values:\")\n",
    "print(df_esg['Controversy Level'].unique())\n",
    "\n",
    "print(\"\\n Unique 'ESG Risk Percentile' values (first 10):\")\n",
    "print(df_esg['ESG Risk Percentile'].unique()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23b0f1",
   "metadata": {},
   "source": [
    "Main Finding: \n",
    "\n",
    "Large Data Gaps. This file is missing a lot of data. Out of 503 companies, 73 are missing all primary ESG data (Total ESG Risk score is 430 non-null). This is a major limitation (503 - 430 = 73). These NaN values are not errors, but they confirm a large portion of the companies are \"Not Rated.\"\n",
    "\n",
    "Main Finding: Dirty Text Columns. The unique outputs confirm our cleaning plan is necessary.\n",
    "\n",
    "Controversy Level: The values are verbose (e.g., 'Moderate Controversy Level'). We must strip the \"Controversy Level\" suffix.\n",
    "\n",
    "ESG Risk Percentile: This is an object (text) column, not numeric (e.g., '50th percentile'). We will have to extract the number.\n",
    "\n",
    "Cleanup and Redundancy:\n",
    "\n",
    "Redundant Columns: The result shows Name and Sector columns, however our df_financials file already has these. Since df_financials is our base table (our \"source of truth\"), the Name and Sector in this file are redundant. We will drop them to prevent a merge conflict (which would create Name_x, Name_y columns).\n",
    "\n",
    "Useless Columns: Address, Full Time Employees, and Description are useless for our KPIs. They're long text fields we can't score or filter on, so they will be dropped.\n",
    "\n",
    "Useful Column: Industry (e.g., \"Solar\") is not in the financial file and is not redundant. It's valuable data for user filtering, so we will keep this column.\n",
    "\n",
    "File Mismatch: This file has 503 entries; the financial file has 505. This confirms our LEFT JOIN strategy is correct. The two companies from the financial list that aren't in this file will correctly show NaN for all ESG fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926666f",
   "metadata": {},
   "source": [
    "#### ***Null Value Analysis (Pre-Transform)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b552607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Financials Nulls:\n",
      "Symbol            0\n",
      "Name              0\n",
      "Sector            0\n",
      "Price             0\n",
      "Price/Earnings    2\n",
      "Dividend Yield    0\n",
      "Earnings/Share    0\n",
      "52 Week Low       0\n",
      "52 Week High      0\n",
      "Market Cap        0\n",
      "EBITDA            0\n",
      "Price/Sales       0\n",
      "Price/Book        8\n",
      "SEC Filings       0\n",
      "dtype: int64\n",
      "\n",
      "ESG Nulls:\n",
      "Symbol                      0\n",
      "Name                        0\n",
      "Address                     1\n",
      "Sector                      1\n",
      "Industry                    1\n",
      "Full Time Employees         5\n",
      "Description                 1\n",
      "Total ESG Risk score       73\n",
      "Environment Risk Score     73\n",
      "Governance Risk Score      73\n",
      "Social Risk Score          73\n",
      "Controversy Level          73\n",
      "Controversy Score         100\n",
      "ESG Risk Percentile        73\n",
      "ESG Risk Level             73\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinancials Nulls:\")\n",
    "print(df_financials.isna().sum())\n",
    "\n",
    "print(\"\\nESG Nulls:\")\n",
    "print(df_esg.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c79b6",
   "metadata": {},
   "source": [
    "Financials (df_financials): The nulls are exactly as we thought. They are minor and acceptable: 2 nulls for Price/Earnings and 8 for Price/Book. This show incomplete data, but not a big issue.\n",
    "\n",
    "ESG (df_esg): This confirms the major data gap. The key KPI columns (Total ESG Risk score, Environment Risk Score, Controversy Level, etc.) are all missing 73 records. This is the \"Not Rated\" group we identified.\n",
    "\n",
    "It also shows that Controversy Score is in even worse shape, with 100 nulls. This just reinforces that the ESG data is spotty, but it doesn't change our plan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa2f3f",
   "metadata": {},
   "source": [
    "#### ***Simulate Proprietary Data (df_proprietary)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7282f3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating Proprietary Data\n",
      "Simulated 505 proprietary scores.\n",
      "Verifying head of simulated data:\n",
      "  Symbol  Proprietary Values Score\n",
      "0    MMM                        78\n",
      "1    AOS                        91\n",
      "2    ABT                        68\n",
      "3   ABBV                        54\n",
      "4    ACN                        82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Simulating Proprietary Data\")\n",
    "\n",
    "# We are going to use symbols from the financials file to ensure a perfect match\n",
    "symbols = df_financials['Symbol'].unique()\n",
    "\n",
    "# Let's now generate a random \"Proprietary Values Score\" between 40 and 100\n",
    "np.random.seed(42) # Use a seed for consistent, repeatable results\n",
    "prop_scores = np.random.randint(40, 101, size=len(symbols))\n",
    "\n",
    "df_proprietary = pd.DataFrame({'Symbol': symbols, 'Proprietary Values Score': prop_scores})\n",
    "\n",
    "print(f\"Simulated {len(df_proprietary)} proprietary scores.\")\n",
    "print(\"Verifying head of simulated data:\")\n",
    "print(df_proprietary.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d042a46",
   "metadata": {},
   "source": [
    "Result: \n",
    "\n",
    "The simulation was successful. It created a new df_proprietary dataframe with 505 records, one for each Symbol in our df_financials base table. The head() output confirms the Proprietary Values Score column is populated with random integers.\n",
    "\n",
    "Why are we doing this? We're simulating this data because the Proprietary Values Score is a critical KPI from our Part 1 business plan. We must have this column to prove our DSS can work as designed. Since we don't have a real file of internal scores, simulating it is the only way to test our complete ETL process. Using the df_financials['Symbol'] as the key guarantees it has the exact same 505 companies as our base table, ensuring a technically perfect merge.\n",
    "\n",
    "Why isn't this introducing bias? Since this data itself is 100% fake and has no real-world correlation, we would not worry about this aspect right now. It's just random numbers. This doesn't introduce bias for the purpose of this project because our goal right now is not to find actual investment insights. Our goal is to prove the technical capability of our ETL process and DSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29e12fd",
   "metadata": {},
   "source": [
    "#### ***Transformation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "858d8e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming Data (based on analysis)\n",
      "T1: Fixing inverted 52-week columns...\n",
      "T2: Cleaning 'Price/Earnings'...\n",
      "T3: Cleaning 'Controversy Level'...\n",
      "T4: Cleaning 'ESG Risk Percentile'...\n",
      "T5: Dropping unneeded and redundant columns...\n",
      "\n",
      "Transformation complete.\n",
      "VERIFY: df_financials columns: ['Symbol', 'Name', 'Sector', 'Price', 'Price/Earnings', 'Dividend Yield', 'Earnings/Share', '52 Week High', '52 Week Low', 'Market Cap', 'EBITDA', 'Price/Sales', 'Price/Book']\n",
      "VERIFY: df_esg columns: ['Symbol', 'Industry', 'Total ESG Risk score', 'Environment Risk Score', 'Governance Risk Score', 'Social Risk Score', 'Controversy Level', 'Controversy Score', 'ESG Risk Percentile', 'ESG Risk Level']\n"
     ]
    }
   ],
   "source": [
    "print(\"Transforming Data (based on analysis)\")\n",
    "\n",
    "# T1: Fix inverted '52 Week Low' and '52 Week High' in df_financials\n",
    "print(\"T1: Fixing inverted 52-week columns...\")\n",
    "df_financials.rename(columns={\n",
    "    '52 Week Low': 'temp_high',\n",
    "    '52 Week High': '52 Week Low'\n",
    "}, inplace=True)\n",
    "df_financials.rename(columns={\n",
    "    'temp_high': '52 Week High'\n",
    "}, inplace=True)\n",
    "\n",
    "# T2: Handleling 'Price/Earnings' and convert to numeric\n",
    "# Ensuring the 2 nulls from Block 5 are handled correctly\n",
    "print(\"T2: Cleaning 'Price/Earnings'...\")\n",
    "df_financials['Price/Earnings'] = pd.to_numeric(df_financials['Price/Earnings'], errors='coerce')\n",
    "\n",
    "# T3: Cleanning 'Controversy Level' strings in df_esg\n",
    "print(\"T3: Cleaning 'Controversy Level'...\")\n",
    "df_esg['Controversy Level'] = df_esg['Controversy Level'].astype(str).str.replace(' Controversy Level', '').str.strip()\n",
    "\n",
    "# T4: Cleanning 'ESG Risk Percentile' strings in df_esg\n",
    "print(\"T4: Cleaning 'ESG Risk Percentile'...\")\n",
    "# Use regex to extract only the digits, then convert to float\n",
    "df_esg['ESG Risk Percentile'] = df_esg['ESG Risk Percentile'].astype(str).str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# T5: Field Selection (Dropping unnecessary columns)\n",
    "print(\"T5: Dropping unneeded and redundant columns...\")\n",
    "# Dropping from financials:\n",
    "df_financials = df_financials.drop(columns=['SEC Filings'])\n",
    "\n",
    "# Dropping from ESG (keeping 'Industry' as we discussed):\n",
    "df_esg = df_esg.drop(columns=[\n",
    "    'Name',                 # Redundant with financials\n",
    "    'Address',              # Useless for KPIs\n",
    "    'Sector',               # Redundant with financials\n",
    "    'Full Time Employees',  # Useless for KPIs\n",
    "    'Description'           # Useless for KPIs\n",
    "])\n",
    "\n",
    "print(\"\\nTransformation complete.\")\n",
    "print(f\"VERIFY: df_financials columns: {list(df_financials.columns)}\")\n",
    "print(f\"VERIFY: df_esg columns: {list(df_esg.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e3efb",
   "metadata": {},
   "source": [
    "#### ***Verification (Post-Transform)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69c6a815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying Transformations ---\n",
      "\n",
      "Financials Numeric Stats (Post-Transform):\n",
      "       52 Week Low  52 Week High\n",
      "count   505.000000    505.000000\n",
      "mean     83.536616    122.623832\n",
      "std     105.725473    155.362140\n",
      "min       2.800000      6.590000\n",
      "25%      38.430000     56.250000\n",
      "50%      62.850000     86.680000\n",
      "75%      96.660000    140.130000\n",
      "max    1589.000000   2067.990000\n",
      "\n",
      "Financials Info (Post-Transform):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Symbol          505 non-null    object \n",
      " 1   Name            505 non-null    object \n",
      " 2   Sector          505 non-null    object \n",
      " 3   Price           505 non-null    float64\n",
      " 4   Price/Earnings  503 non-null    float64\n",
      " 5   Dividend Yield  505 non-null    float64\n",
      " 6   Earnings/Share  505 non-null    float64\n",
      " 7   52 Week High    505 non-null    float64\n",
      " 8   52 Week Low     505 non-null    float64\n",
      " 9   Market Cap      505 non-null    int64  \n",
      " 10  EBITDA          505 non-null    float64\n",
      " 11  Price/Sales     505 non-null    float64\n",
      " 12  Price/Book      497 non-null    float64\n",
      "dtypes: float64(9), int64(1), object(3)\n",
      "memory usage: 51.4+ KB\n",
      "\n",
      "ESG Unique Values (Post-Transform):\n",
      "['nan' 'Moderate' 'Low' 'Severe' 'None' 'Significant' 'High']\n",
      "\n",
      "ESG Head (Post-Transform):\n",
      "  Symbol                 Industry  Total ESG Risk score  \\\n",
      "0   ENPH                    Solar                   NaN   \n",
      "1    EMN      Specialty Chemicals                  25.3   \n",
      "2    DPZ              Restaurants                  29.2   \n",
      "3    DAY   Software - Application                   NaN   \n",
      "4    DVA  Medical Care Facilities                  22.6   \n",
      "\n",
      "   Environment Risk Score  Governance Risk Score  Social Risk Score  \\\n",
      "0                     NaN                    NaN                NaN   \n",
      "1                    12.8                    6.6                5.8   \n",
      "2                    10.6                    6.3               12.2   \n",
      "3                     NaN                    NaN                NaN   \n",
      "4                     0.1                    8.4               14.1   \n",
      "\n",
      "  Controversy Level  Controversy Score  ESG Risk Percentile ESG Risk Level  \n",
      "0               nan                NaN                  NaN            NaN  \n",
      "1          Moderate                2.0                 50.0         Medium  \n",
      "2          Moderate                2.0                 66.0         Medium  \n",
      "3               nan                NaN                  NaN            NaN  \n",
      "4          Moderate                2.0                 38.0         Medium  \n"
     ]
    }
   ],
   "source": [
    "print(\"--- Verifying Transformations ---\")\n",
    "\n",
    "print(\"\\nFinancials Numeric Stats (Post-Transform):\")\n",
    "# This check proves the 52-week columns are fixed.\n",
    "# The mean High should now be > mean Low.\n",
    "print(df_financials[['52 Week Low', '52 Week High']].describe())\n",
    "\n",
    "print(\"\\nFinancials Info (Post-Transform):\")\n",
    "# This check proves 'Price/Earnings' is now float64\n",
    "df_financials.info()\n",
    "\n",
    "print(\"\\nESG Unique Values (Post-Transform):\")\n",
    "# This check proves 'Controversy Level' is clean\n",
    "print(df_esg['Controversy Level'].unique())\n",
    "\n",
    "print(\"\\nESG Head (Post-Transform):\")\n",
    "# This check proves 'ESG Risk Percentile' is now a number (float64)\n",
    "# and that 'Industry' was kept.\n",
    "print(df_esg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b3071",
   "metadata": {},
   "source": [
    "Main Fix Verified: \n",
    "\n",
    "The output confirms our primary fix. The 52 Week High (mean $122.62) is now correctly greater than the 52 Week Low (mean $83.53). The columns are no longer inverted.\n",
    "\n",
    "Text Cleanup Verified: The [ESG Unique Values] output proves our string cleaning worked. The Controversy Level column is now a clean list of single-word categories (['Moderate', 'Low', 'Severe', 'None', 'Significant', 'High']) instead of verbose sentences.\n",
    "\n",
    "Numeric Conversion Verified: The [ESG Head] output shows ESG Risk Percentile is now a clean number (e.g., 50.0, 66.0), not a text string. The [Financials Info] block also confirms Price/Earnings is correctly typed as float64.\n",
    "\n",
    "Column Selection Verified: The [ESG Head] output confirms our plan to keep the Industry column was successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51734d81",
   "metadata": {},
   "source": [
    "#### ***Load (Merge)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9c4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 4: Loading (Merging) Data ---\n",
      "Merging Financials and ESG data (LEFT JOIN)...\n",
      "Merging result with Proprietary data (LEFT JOIN)...\n",
      "Merge complete. Final dataframe has 505 rows.\n",
      "--- Verifying head of final merged data ---\n",
      "  Symbol                 Name                  Sector   Price  Price/Earnings  \\\n",
      "0    MMM           3M Company             Industrials  222.89           24.31   \n",
      "1    AOS      A.O. Smith Corp             Industrials   60.24           27.76   \n",
      "2    ABT  Abbott Laboratories             Health Care   56.27           22.51   \n",
      "3   ABBV          AbbVie Inc.             Health Care  108.48           19.41   \n",
      "4    ACN        Accenture plc  Information Technology  150.51           25.47   \n",
      "\n",
      "   Dividend Yield  Earnings/Share  52 Week High  52 Week Low    Market Cap  \\\n",
      "0        2.332862            7.92        259.77      175.490  138721055226   \n",
      "1        1.147959            1.70         68.39       48.925   10783419933   \n",
      "2        1.908982            0.26         64.60       42.280  102121042306   \n",
      "3        2.499560            3.29        125.86       60.050  181386347059   \n",
      "4        1.714470            5.44        162.60      114.820   98765855553   \n",
      "\n",
      "   ...                         Industry  Total ESG Risk score  \\\n",
      "0  ...                    Conglomerates                  37.3   \n",
      "1  ...   Specialty Industrial Machinery                  25.4   \n",
      "2  ...                  Medical Devices                  24.8   \n",
      "3  ...     Drug Manufacturers - General                  29.9   \n",
      "4  ...  Information Technology Services                   9.8   \n",
      "\n",
      "   Environment Risk Score Governance Risk Score  Social Risk Score  \\\n",
      "0                    17.2                   6.5               13.6   \n",
      "1                     7.2                   6.4               11.9   \n",
      "2                     2.3                   8.3               14.2   \n",
      "3                     2.4                  10.4               17.2   \n",
      "4                     0.8                   4.4                4.6   \n",
      "\n",
      "   Controversy Level  Controversy Score  ESG Risk Percentile ESG Risk Level  \\\n",
      "0             Severe                5.0                 89.0           High   \n",
      "1                Low                1.0                 51.0         Medium   \n",
      "2        Significant                3.0                 48.0         Medium   \n",
      "3        Significant                3.0                 69.0         Medium   \n",
      "4           Moderate                2.0                  3.0     Negligible   \n",
      "\n",
      "   Proprietary Values Score  \n",
      "0                        78  \n",
      "1                        91  \n",
      "2                        68  \n",
      "3                        54  \n",
      "4                        82  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading (Merging) Data\")\n",
    "\n",
    "# L1: We will merge Financials (base) with ESG data\n",
    "# Using a LEFT JOIN to keep all 505 financial records\n",
    "print(\"Merging Financials and ESG data (LEFT JOIN)...\")\n",
    "df_merged = pd.merge(df_financials, df_esg, on='Symbol', how='left')\n",
    "\n",
    "# L2: Then we will merge the result with Proprietary data\n",
    "# Using a LEFT JOIN again to keep all 505 records\n",
    "print(\"Merging result with Proprietary data (LEFT JOIN)...\")\n",
    "df_final = pd.merge(df_merged, df_proprietary, on='Symbol', how='left')\n",
    "\n",
    "print(f\"Merge complete. Final dataframe has {len(df_final)} rows.\")\n",
    "print(\"--- Verifying head of final merged data ---\")\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb79594",
   "metadata": {},
   "source": [
    "The merge was successful, and our LEFT JOIN strategy worked perfectly.\n",
    "\n",
    "Row Count: The output Merge complete. Final dataframe has 505 rows. confirms our logic was sound. We started with 505 financial records, joined them against 503 ESG records and 505 proprietary records, and correctly ended with 505 rows. No companies were lost.\n",
    "\n",
    "Schema: The head() output is the first look at our final, unified dataset. It visually confirms that all our key columns from all three sources are now in a single row for each company:\n",
    "\n",
    "Financial data (e.g., Price, 52 Week High/Low)\n",
    "\n",
    "ESG data (e.g., Industry, Total ESG Risk score)\n",
    "\n",
    "Proprietary data (e.g., Proprietary Values Score)\n",
    "\n",
    "No Conflicts: Critically, there are no Name_x, Name_y columns. This proves that our transformation step to drop the redundant Name and Sector columns from the ESG file was the correct decision and prevented a messy merge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f395b899",
   "metadata": {},
   "source": [
    "#### ***Final Analysis (Merged Data)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a062eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Analysis of Merged Data ---\n",
      "\n",
      "Final Schema and Data Types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Symbol                    505 non-null    object \n",
      " 1   Name                      505 non-null    object \n",
      " 2   Sector                    505 non-null    object \n",
      " 3   Price                     505 non-null    float64\n",
      " 4   Price/Earnings            503 non-null    float64\n",
      " 5   Dividend Yield            505 non-null    float64\n",
      " 6   Earnings/Share            505 non-null    float64\n",
      " 7   52 Week High              505 non-null    float64\n",
      " 8   52 Week Low               505 non-null    float64\n",
      " 9   Market Cap                505 non-null    int64  \n",
      " 10  EBITDA                    505 non-null    float64\n",
      " 11  Price/Sales               505 non-null    float64\n",
      " 12  Price/Book                497 non-null    float64\n",
      " 13  Industry                  378 non-null    object \n",
      " 14  Total ESG Risk score      368 non-null    float64\n",
      " 15  Environment Risk Score    368 non-null    float64\n",
      " 16  Governance Risk Score     368 non-null    float64\n",
      " 17  Social Risk Score         368 non-null    float64\n",
      " 18  Controversy Level         379 non-null    object \n",
      " 19  Controversy Score         349 non-null    float64\n",
      " 20  ESG Risk Percentile       368 non-null    float64\n",
      " 21  ESG Risk Level            368 non-null    object \n",
      " 22  Proprietary Values Score  505 non-null    int32  \n",
      "dtypes: float64(15), int32(1), int64(1), object(6)\n",
      "memory usage: 88.9+ KB\n",
      "\n",
      "Final Null Counts (Post-Merge):\n",
      "Symbol                        0\n",
      "Name                          0\n",
      "Sector                        0\n",
      "Price                         0\n",
      "Price/Earnings                2\n",
      "Dividend Yield                0\n",
      "Earnings/Share                0\n",
      "52 Week High                  0\n",
      "52 Week Low                   0\n",
      "Market Cap                    0\n",
      "EBITDA                        0\n",
      "Price/Sales                   0\n",
      "Price/Book                    8\n",
      "Industry                    127\n",
      "Total ESG Risk score        137\n",
      "Environment Risk Score      137\n",
      "Governance Risk Score       137\n",
      "Social Risk Score           137\n",
      "Controversy Level           126\n",
      "Controversy Score           156\n",
      "ESG Risk Percentile         137\n",
      "ESG Risk Level              137\n",
      "Proprietary Values Score      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Final Analysis of Merged Data ---\")\n",
    "\n",
    "print(\"\\nFinal Schema and Data Types:\")\n",
    "df_final.info()\n",
    "\n",
    "print(\"\\nFinal Null Counts (Post-Merge):\")\n",
    "print(df_final.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f15e1",
   "metadata": {},
   "source": [
    "Main Finding: \n",
    "\n",
    "Critical Data Mismatch. This is the most important finding of the entire ETL process. The [Final Null Counts] show 137 nulls for Total ESG Risk score and all other key ESG fields. This proves our two Kaggle files are not clean subsets of each other. This is the real-world data problem that we would face.\n",
    "\n",
    "Here's the evidence from the numbers:\n",
    "\n",
    "Our df_esg file (Block 4) had 430 companies with ESG scores.\n",
    "\n",
    "Our final unified file only has 368 companies with ESG scores (505 total rows - 137 nulls).\n",
    "\n",
    "This means 62 companies (430 - 368) that had an ESG score were discarded during the merge. Why? Because their Symbols (ticker) didn't exist in our df_financials base file.\n",
    "\n",
    "This also means 137 companies from our df_financials base file have no ESG data. This is the true number of \"Not Rated\" companies in our final universe.\n",
    "\n",
    "This isn't a failure. This is the finding. We were able to identified and quantified a major data integrity issue particularly in this case. Our final dataset for the dashboard will be based on the 368 companies where we have a complete match.\n",
    "\n",
    "Minor Findings:\n",
    "\n",
    "The original Price/Earnings (2 nulls) and Price/Book (8 nulls) counts are unchanged. This is correct.\n",
    "\n",
    "Proprietary Values Score has 0 nulls, which is correct for our simulation.\n",
    "\n",
    "Conclusion: The data is now fully unified. We have all the evidence for our report, including the critical mismatch we just found. All analysis is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce47fb9",
   "metadata": {},
   "source": [
    "#### ***Save Output Files***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Output Files\n",
      "\n",
      "Successfully created 'pdss_unified_dataset.csv' and 'pdss_data_sample.csv'\n",
      "--- ETL Process Complete ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving Output Files\")\n",
    "df_final.to_csv(r\"C:\\your_user\\your_folder\\pdss_unified_dataset.csv\", index=False)\n",
    "\n",
    "# Saving the 100-record sample for the assignment submission\n",
    "df_final.head(100).to_csv(r\"C:\\your_user\\your_folder\\pdss_data_sample.csv\", index=False)\n",
    "print(\"\\nSuccessfully created 'pdss_unified_dataset.csv' and 'pdss_data_sample.csv'\")\n",
    "print(\"--- ETL Process Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c86e1d6",
   "metadata": {},
   "source": [
    "#### ***Loading to MySQL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40901c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data into MySQL Database\n",
      "Success: 505 rows loaded into table 'investment_universe'.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database Connection Configuration\n",
    "db_user = 'root'\n",
    "db_password = 'your_password'\n",
    "db_host = 'localhost'\n",
    "db_port = '3306'\n",
    "db_name = 'wealth_management_dss'\n",
    "\n",
    "# Creating SQLAlchemy Engine\n",
    "connection_str = f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "engine = create_engine(connection_str)\n",
    "\n",
    "print(\"Loading Data into MySQL Database\")\n",
    "\n",
    "# We need to rename columns to match the SQL Schema format (removing spaces/slashes)\n",
    "df_sql = df_final.copy()\n",
    "df_sql.columns = [\n",
    "    'symbol', 'company_name', 'sector', 'current_price', 'pe_ratio', \n",
    "    'dividend_yield', 'earnings_per_share', 'week_52_high', 'week_52_low', \n",
    "    'market_cap', 'ebitda', 'price_to_sales', 'price_to_book', 'industry', \n",
    "    'total_esg_risk', 'environment_risk', 'governance_risk', 'social_risk', \n",
    "    'controversy_level', 'controversy_score', 'esg_risk_percentile', \n",
    "    'esg_risk_level', 'proprietary_score'\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Writting data to MySQL\n",
    "    # if_exists='replace' will drop the table and recreate it every time we run the ETL\n",
    "    # if_exists='append' would add duplicates if we aren't careful\n",
    "    df_sql.to_sql('investment_universe', con=engine, if_exists='replace', index=False)\n",
    "    print(f\"Success: {len(df_sql)} rows loaded into table 'investment_universe'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to database: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
